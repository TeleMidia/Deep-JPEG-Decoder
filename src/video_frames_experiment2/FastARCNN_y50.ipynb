{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from lib.models.FastARCNN import FastARCNN\n",
    "import lib.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set experiment ID\n",
    "Y_QUALITY = 50 #y=50, y=40, y=30\n",
    "EXP_ID = \"FastARCNN_y\"+str(Y_QUALITY)\n",
    "utils.create_experiment_folders(EXP_ID)\n",
    "utils.load_experiment_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = FastARCNN()\n",
    "model.build((None,120,120,3))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading the training dataset\n",
    "train_x, train_y = utils.load_dataset(\"../../dataset/dataset_video_frames2/train\",  limit=None, inRoot=True, y_quality=Y_QUALITY) \n",
    "\n",
    "print(\"Loaded\",train_x.shape[0], \"samples\")\n",
    "\n",
    "#check the five firts samples   \n",
    "utils.show_samples(train_x, train_y, begin=0, end=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading the training dataset\n",
    "valid_x, valid_y = utils.load_dataset(\"../../dataset/dataset_video_frames2/valid\",  limit=None, inRoot=True, y_quality=Y_QUALITY) \n",
    "\n",
    "print(\"Loaded\",valid_x.shape[0], \"samples\")\n",
    "\n",
    "#check the five firts samples   \n",
    "utils.show_samples(valid_x, valid_y, begin=0, end=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset shift and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFT_VALUE_X, SHIFT_VALUE_Y, SCALE_VALUE_X, SCALE_VALUE_Y = utils.get_shift_scale_maxmin(train_x, train_y, valid_x, valid_y)\n",
    "\n",
    "train_x = utils.shift_and_normalize(train_x, SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "train_y = utils.shift_and_normalize(train_y, SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "\n",
    "valid_x = utils.shift_and_normalize(valid_x, SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "valid_y = utils.shift_and_normalize(valid_y, SHIFT_VALUE_Y, SCALE_VALUE_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = utils.random_mini_batches(train_x, train_y, 8, seed=0)\n",
    "valid_batches = utils.random_mini_batches(valid_x, valid_y, 8, seed=0)\n",
    "print(\"train_batches:\", len(train_batches), \"valid_batches:\", len(valid_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default tf.keras metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "valid_mse = tf.keras.metrics.MeanSquaredError(name='train_mse')\n",
    "\n",
    "#psnr, ssim and nrmse\n",
    "valid_custom_metrics = utils.CustomMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Loss and load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#get last saved epoch index and best result in validation step\n",
    "CURRENT_EPOCH, BEST_VALIDATION = utils.get_model_last_data()\n",
    "if CURRENT_EPOCH > 0:\n",
    "    print(\"Loading last model state in epoch\", CURRENT_EPOCH)\n",
    "    model.load_weights(utils.get_exp_folder_last_epoch())\n",
    "    print(\"Best validation result was SSIM=\", BEST_VALIDATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image_x, image_y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(image_x)\n",
    "        loss = loss_object(image_y, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "\n",
    "MAX_EPOCHS = 401\n",
    "EVAL_STEP = 20\n",
    "\n",
    "for epoch in range(CURRENT_EPOCH, MAX_EPOCHS):\n",
    "    \n",
    "    #TRAINING\n",
    "    print(\"TRAINING EPOCH\", epoch)\n",
    "   \n",
    "    for batch in train_batches:\n",
    "        (batch_x, batch_y) = batch\n",
    "        train_step(batch_x, batch_y)\n",
    "    \n",
    "    #VALIDATION\n",
    "    if epoch%EVAL_STEP == 0 and epoch > 0:\n",
    "        #tf.keras.backend.set_learning_phase(0)\n",
    "        clear_output()\n",
    "        \n",
    "        print(\"VALIDATION EPOCH\", epoch)\n",
    "        #saving last epoch model\n",
    "        model.save_weights(utils.get_exp_folder_last_epoch(), save_format='tf')\n",
    "        for index, batch in enumerate(valid_batches):\n",
    "            (batch_x, batch_y) = batch\n",
    "            predictions = model(batch_x)\n",
    "            valid_mse(batch_y, predictions)\n",
    "            \n",
    "            # convert back to original pattern\n",
    "            batch_x = utils.inv_shift_and_normalize(batch_x.copy(), SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "            batch_y = utils.inv_shift_and_normalize(batch_y.copy(), SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "            predictions = utils.inv_shift_and_normalize(predictions.numpy(), SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "            \n",
    "            #convert from frequency to pixel-rgb domain\n",
    "            batch_x, batch_y, predictions = utils.convert_batch_dct2rgb(batch_x, batch_y, predictions)\n",
    "            \n",
    "            #feed the metric evaluator\n",
    "            valid_custom_metrics.feed(batch_y, predictions)\n",
    "            \n",
    "            #just show the first example of batch-0\n",
    "            if index == 0:\n",
    "                print(\"JPEG Q10 - JPEG Q50 - PREDICT\")\n",
    "                utils.preview_sample(batch_x[0], batch_y[0], predictions[0])\n",
    "        \n",
    "        #get metric results\n",
    "        psnr, ssim, nrmse = valid_custom_metrics.result()\n",
    "        valid_mse_result = valid_mse.result().numpy()\n",
    "        \n",
    "        utils.update_chart_data(epoch=epoch, train_mse=train_loss.result().numpy(), \n",
    "                                valid_mse=valid_mse_result, psnr=psnr, ssim=ssim, nrmse=nrmse)\n",
    "        utils.draw_chart()\n",
    "        \n",
    "        #saving best validation model\n",
    "        if ssim > BEST_VALIDATION:\n",
    "            BEST_VALIDATION = ssim\n",
    "            model.save_weights(utils.get_exp_folder_best_valid(), save_format='tf')\n",
    "        \n",
    "    train_loss.reset_states()\n",
    "    valid_mse.reset_states()\n",
    "    valid_custom_metrics.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model with best SSIM\n",
    "model.load_weights(utils.get_exp_folder_best_valid())\n",
    "\n",
    "\n",
    "for img_index in range(0, valid_x.shape[0]):\n",
    "    img_x = valid_x[img_index:(img_index+1)]\n",
    "    img_y = valid_y[img_index:(img_index+1)]\n",
    "    prediction = model(img_x)\n",
    "\n",
    "    img_x = utils.inv_shift_and_normalize(img_x.copy(), SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "    img_y = utils.inv_shift_and_normalize(img_y.copy(), SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "    prediction = utils.inv_shift_and_normalize(prediction.numpy(), SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "\n",
    "    #convert from frequency to pixel-rgb domain\n",
    "    img_x, img_y, prediction = utils.convert_batch_dct2rgb(img_x, img_y, prediction)\n",
    "    print(\"JPEG Q10 - JPEG Q50 - PREDICT\")\n",
    "    utils.preview_sample(img_x[0], img_y[0], prediction[0])\n",
    "    plt.pause(0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading the training dataset\n",
    "test_x, test_y = utils.load_dataset(\"../../dataset/dataset_video_frames2/test\",  limit=None, inRoot=True, y_quality=Y_QUALITY)\n",
    "\n",
    "print(\"Loaded\",test_x.shape[0], \"samples\")\n",
    "\n",
    "#check the five firts samples   \n",
    "utils.show_samples(test_x, test_y, begin=0, end=5)\n",
    "\n",
    "test_x = utils.shift_and_normalize(test_x, SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "test_y = utils.shift_and_normalize(test_y, SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "\n",
    "test_batches = utils.random_mini_batches(test_x, test_y, 8, seed=0)\n",
    "\n",
    "for index, batch in enumerate(test_batches):\n",
    "    (batch_x, batch_y) = batch\n",
    "    predictions = model(batch_x)\n",
    "\n",
    "    # convert back to original pattern\n",
    "    batch_x = utils.inv_shift_and_normalize(batch_x.copy(), SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "    batch_y = utils.inv_shift_and_normalize(batch_y.copy(), SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "    predictions = utils.inv_shift_and_normalize(predictions.numpy(), SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "            \n",
    "    #convert from frequency to pixel-rgb domain\n",
    "    batch_x, batch_y, predictions = utils.convert_batch_dct2rgb(batch_x, batch_y, predictions)\n",
    "            \n",
    "    #feed the metric evaluator\n",
    "    valid_custom_metrics.feed(batch_y, predictions)\n",
    "\n",
    "#get metric results\n",
    "psnr, ssim, nrmse = valid_custom_metrics.result()\n",
    "print(\"Results for test set\")\n",
    "print(\"SSIM\", ssim)\n",
    "print(\"PSNR\", psnr)\n",
    "print(\"NRMSE\", nrmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test with full frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lib.jpeg as jpg\n",
    "import cv2\n",
    "\n",
    "frame_path = \"../../dataset/dataset_video_frames/full_frame_test/2.jpg\"\n",
    "\n",
    "qtable_luma_50, qtable_chroma_50 = jpg.generate_qtables(quality_factor=50)\n",
    "qtable_luma_10, qtable_chroma_10 = jpg.generate_qtables(quality_factor=10)\n",
    "\n",
    "frame = utils.open_image(frame_path)\n",
    "\n",
    "qtdy_patches = (frame.shape[0]/120)*(frame.shape[1]/120)\n",
    "\n",
    "frame_q10 = np.zeros(frame.shape, dtype=np.uint8)\n",
    "frame_q50 = np.zeros(frame.shape, dtype=np.uint8)\n",
    "frame_pred = np.zeros(frame.shape, dtype=np.uint8)\n",
    "\n",
    "print(qtdy_patches)\n",
    "\n",
    "for i in range(0, frame.shape[0],120):\n",
    "    for j in range(0, frame.shape[1],120):\n",
    "        pos_x = (i*120)\n",
    "        pos_y = (j*120)\n",
    "        patch = frame[i:(i+120),j:(j+120),:]\n",
    "        dct_q10 = jpg.encode_image(patch, qtable_luma_10, qtable_chroma_10)\n",
    "        dct_q10 = np.expand_dims(dct_q10, axis=0)\n",
    "        dct_q10 = utils.shift_and_normalize(dct_q10, SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "        dct_q50 = jpg.encode_image(patch, qtable_luma_50, qtable_chroma_50)\n",
    "        dct_q50 = np.expand_dims(dct_q50, axis=0)\n",
    "        dct_q50 = utils.shift_and_normalize(dct_q50, SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "        prediction = model(dct_q10)\n",
    "        \n",
    "        # convert back to original pattern\n",
    "        dct_q10 = utils.inv_shift_and_normalize(dct_q10.copy(), SHIFT_VALUE_X, SCALE_VALUE_X)\n",
    "        dct_q50 = utils.inv_shift_and_normalize(dct_q50.copy(), SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "        prediction = utils.inv_shift_and_normalize(prediction.numpy(), SHIFT_VALUE_Y, SCALE_VALUE_Y)\n",
    "            \n",
    "        #convert from frequency to pixel-rgb domain\n",
    "        img_q10, img_q50, prediction = utils.convert_batch_dct2rgb(dct_q10, dct_q50, prediction)\n",
    "        \n",
    "        frame_q10[i:(i+120),j:(j+120),:] = img_q10\n",
    "        frame_q50[i:(i+120),j:(j+120),:] = img_q50\n",
    "        frame_pred[i:(i+120),j:(j+120),:] = prediction\n",
    "        \n",
    "        utils.preview_sample(img_q10[0], img_q50[0], prediction[0])\n",
    "        \n",
    "        plt.pause(0.1)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"frame_q10.jpg\", cv2.cvtColor(frame_q10, cv2.COLOR_RGB2BGR), [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "cv2.imwrite(\"frame_q50.jpg\", cv2.cvtColor(frame_q50, cv2.COLOR_RGB2BGR), [int(cv2.IMWRITE_JPEG_QUALITY), 100])   \n",
    "cv2.imwrite(\"frame_pred.jpg\", cv2.cvtColor(frame_pred, cv2.COLOR_RGB2BGR), [int(cv2.IMWRITE_JPEG_QUALITY), 100])   \n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
